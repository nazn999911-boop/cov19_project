{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c380f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nazarov A.I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3eb49-7a3c-4398-b22c-27dd59172e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Core libraries\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# PyTensor (replaces Theano)\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "# --- 1D convolution using pytensor.scan ---\n",
    "def conv1d(x, w, border_mode=\"valid\"):\n",
    "    \"\"\"1D convolution implemented in PyTensor (symbolic).\"\"\"\n",
    "    x = x[0]  # input sequence\n",
    "    w = w[0]  # convolution kernel\n",
    "    n_x = x.shape[0]\n",
    "    n_w = w.shape[0]\n",
    "\n",
    "    # output length by mode\n",
    "    if border_mode == \"valid\":          # only full overlaps\n",
    "        out_len = n_x - n_w + 1\n",
    "        i_seq = pt.arange(out_len)\n",
    "    elif border_mode == \"full\":         # include partial overlaps\n",
    "        out_len = n_x + n_w - 1\n",
    "        i_seq = pt.arange(out_len)\n",
    "    else:\n",
    "        raise ValueError(\"border_mode must be 'valid' or 'full'\")\n",
    "\n",
    "    # single convolution step\n",
    "    def step(i, x, w):\n",
    "        start = pt.maximum(0, i - n_w + 1)      # start index\n",
    "        end = pt.minimum(i + 1, n_x)            # end index\n",
    "        x_slice = x[start:end]                  # signal window\n",
    "        w_slice = w[n_w - (end - start):n_w]    # reversed kernel window\n",
    "        return pt.sum(x_slice * w_slice)        # dot product\n",
    "\n",
    "    # scan over indices\n",
    "    outputs, _ = pytensor.scan(fn=step, sequences=i_seq, non_sequences=[x, w])\n",
    "    return outputs[None, :]  # restore batch dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2603832-73c9-43fd-a879-242f9626e64e",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecb8e2-8b5e-44c0-8d5c-f591ad910491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер данных: (201018, 67)\n",
      "Количество местоположений: 244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location       date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan 2020-02-24          5.0        5.0   \n",
       "1      AFG      Asia  Afghanistan 2020-02-25          5.0        0.0   \n",
       "2      AFG      Asia  Afghanistan 2020-02-26          5.0        0.0   \n",
       "3      AFG      Asia  Afghanistan 2020-02-27          5.0        0.0   \n",
       "4      AFG      Asia  Afghanistan 2020-02-28          5.0        0.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "1                 NaN           NaN         NaN                  NaN  ...   \n",
       "2                 NaN           NaN         NaN                  NaN  ...   \n",
       "3                 NaN           NaN         NaN                  NaN  ...   \n",
       "4                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                  37.746   \n",
       "1             NaN           NaN                  37.746   \n",
       "2             NaN           NaN                  37.746   \n",
       "3             NaN           NaN                  37.746   \n",
       "4             NaN           NaN                  37.746   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                         0.5            64.83                    0.511   \n",
       "1                         0.5            64.83                    0.511   \n",
       "2                         0.5            64.83                    0.511   \n",
       "3                         0.5            64.83                    0.511   \n",
       "4                         0.5            64.83                    0.511   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/owid-covid-data.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "print('Size of data:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abaae8d-df04-4c9e-a78c-915d2d6de5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data: pd.DataFrame):\n",
    "    \"\"\"Process data for the task.\"\"\"\n",
    "    data = data[['location', 'date', 'total_cases', 'new_cases', 'reproduction_rate']]\n",
    "    data = data[data.location.isin(['Russia', 'Italy', 'Germany', 'France'])]\n",
    "    data = data.rename(columns={'total_cases': 'total', 'new_cases': 'positive'})\n",
    "    data.set_index('date', inplace=True)\n",
    "\n",
    "    # --- Clean up missing or bad values ---\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)  # drop infinities\n",
    "    data = data.fillna(0)  # fill any NaNs with 0\n",
    "    data['positive'] = data['positive'].astype('float32')\n",
    "    data['total'] = data['total'].astype('float32')\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cd6310-4b67-4969-96bd-f4c59d6edad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total</th>\n",
       "      <th>positive</th>\n",
       "      <th>reproduction_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>France</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>France</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>France</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-27</th>\n",
       "      <td>France</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-28</th>\n",
       "      <td>France</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location  total  positive  reproduction_rate\n",
       "date                                                   \n",
       "2020-01-24   France    2.0       2.0                0.0\n",
       "2020-01-25   France    3.0       1.0                0.0\n",
       "2020-01-26   France    3.0       0.0                0.0\n",
       "2020-01-27   France    3.0       0.0                0.0\n",
       "2020-01-28   France    4.0       1.0                0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оставляем только нужные нам данные: регион, дата, общее число случаев, новые случаи, репродуктивное число\n",
    "# R_t, чтобы потом сравнить с расчетами :)\n",
    "data = process_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff76e-62fc-4c48-942e-251cdad1230c",
   "metadata": {},
   "source": [
    "# PyMC5 Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af01dc4-cc3b-4e42-9985-e0bcf77e2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "#  Imports\n",
    "# ==============================================================\n",
    "\n",
    "import pymc as pm                 # Bayesian modeling and inference\n",
    "import arviz as az                # Analysis and diagnostics of PyMC traces\n",
    "import numpy as np                # Numerical array handling\n",
    "import pandas as pd               # Time-series and tabular data handling\n",
    "from scipy import stats as sps    # Statistical distributions (for delay & gen. time)\n",
    "import pytensor                   # Symbolic math backend (successor of Theano)\n",
    "import pytensor.tensor as pt      # Tensor operations (similar to NumPy ops in graphs)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#  Delay Distribution\n",
    "# ==============================================================\n",
    "\n",
    "def get_delay_distribution():\n",
    "    \"\"\"Create discrete log-normal delay between infection and case confirmation.\"\"\"\n",
    "    mean_delay = 8.0              # average delay (days) from infection to reporting\n",
    "    std_delay = 2.0               # standard deviation of delay (days)\n",
    "\n",
    "    # convert mean/std to log-normal μ and σ on log scale\n",
    "    mu = np.log(mean_delay**2 / np.sqrt(std_delay**2 + mean_delay**2))\n",
    "    sigma = np.sqrt(np.log(std_delay**2 / mean_delay**2 + 1))\n",
    "\n",
    "    # continuous log-normal distribution for delay\n",
    "    dist = sps.lognorm(scale=np.exp(mu), s=sigma)\n",
    "\n",
    "    # days grid (0–19 days)\n",
    "    days = np.arange(0, 20)\n",
    "\n",
    "    # discrete daily probabilities = CDF differences\n",
    "    cdf = dist.cdf(days)\n",
    "    pdf = np.diff(cdf, prepend=0)\n",
    "\n",
    "    # normalize to make sum(pdf) = 1\n",
    "    pdf /= pdf.sum()\n",
    "\n",
    "    # float32 for PyTensor compatibility (less memory, GPU-friendly)\n",
    "    return pdf.astype(\"float32\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#  GenerativeModel: Bayesian time-varying Rₜ estimation\n",
    "# ==============================================================\n",
    "\n",
    "class GenerativeModel:\n",
    "    \"\"\"Probabilistic generative model linking infections to reported cases.\"\"\"\n",
    "    version = \"2.0.0-pymc5\"       # model version string for reproducibility\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    #  Initialization\n",
    "    # ----------------------------------------------------------\n",
    "    def __init__(self, region: str, observed: pd.DataFrame, buffer_days=10):\n",
    "        # locate first nonzero 'positive' entry to remove leading zeros\n",
    "        first_index = observed.positive.ne(0).argmax()\n",
    "\n",
    "        # trim dataset to start from first detected case\n",
    "        observed = observed.iloc[first_index:]\n",
    "\n",
    "        # extend timeline backward by 'buffer_days' of zeros for initial infection seeding\n",
    "        new_index = pd.date_range(\n",
    "            start=observed.index[0] - pd.Timedelta(days=buffer_days),  # start earlier\n",
    "            end=observed.index[-1],                                    # keep same end\n",
    "            freq=\"D\",                                                  # daily frequency\n",
    "        )\n",
    "\n",
    "        # reindex data (prepend zeros)\n",
    "        observed = observed.reindex(new_index, fill_value=0)\n",
    "\n",
    "        # save data and initialize internal containers\n",
    "        self.region = region                  # name of geographic region\n",
    "        self.observed = observed              # input observed dataframe\n",
    "        self._trace = None                    # posterior samples\n",
    "        self._inference_data = None           # ArviZ-formatted samples\n",
    "        self.model = None                     # PyMC model object\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    #  Diagnostics / Posterior Access\n",
    "    # ----------------------------------------------------------\n",
    "    @property\n",
    "    def n_divergences(self):\n",
    "        \"\"\"Return number of NUTS divergences (diagnostic metric).\"\"\"\n",
    "        assert self._trace is not None, \"Must run sample() first\"\n",
    "        return self._trace[\"diverging\"].nonzero()[0].size  # count divergent transitions\n",
    "\n",
    "    @property\n",
    "    def inference_data(self):\n",
    "        \"\"\"Return posterior samples + posterior predictive.\"\"\"\n",
    "        assert self._trace is not None, \"Must run sample() first\"\n",
    "\n",
    "        # generate posterior predictive samples\n",
    "        with self.model:\n",
    "            posterior_predictive = pm.sample_posterior_predictive(self._trace)\n",
    "\n",
    "        # convert PyMC trace into ArviZ object\n",
    "        idata = az.from_pymc(\n",
    "            posterior=self._trace,\n",
    "            posterior_predictive=posterior_predictive,\n",
    "        )\n",
    "\n",
    "        # attach model version metadata\n",
    "        idata.posterior.attrs[\"model_version\"] = self.version\n",
    "        return idata\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    #  Internal helper: scaling\n",
    "    # ----------------------------------------------------------\n",
    "    def _scale_to_positives(self, data):\n",
    "        \"\"\"Scale arbitrary series to match mean of observed positives.\"\"\"\n",
    "        scale_factor = self.observed.positive.mean() / np.mean(data)\n",
    "        return scale_factor * data\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    #  Internal helper: generation-time distribution\n",
    "    # ----------------------------------------------------------\n",
    "    def _get_generation_time_interval(self):\n",
    "        \"\"\"Discrete serial interval (infection→infection delay).\"\"\"\n",
    "        mean_si, std_si = 4.7, 2.9               # mean/std of serial interval (days)\n",
    "\n",
    "        # convert to log-normal μ, σ\n",
    "        mu_si = np.log(mean_si**2 / np.sqrt(std_si**2 + mean_si**2))\n",
    "        sigma_si = np.sqrt(np.log(std_si**2 / mean_si**2 + 1))\n",
    "\n",
    "        # continuous log-normal distribution\n",
    "        dist = sps.lognorm(scale=np.exp(mu_si), s=sigma_si)\n",
    "\n",
    "        # discrete support (0–19 days)\n",
    "        g_range = np.arange(0, 20)\n",
    "\n",
    "        # discrete probability mass from CDF differences\n",
    "        gt = np.diff(dist.cdf(g_range), prepend=0)\n",
    "        gt /= gt.sum()                          # normalize\n",
    "        return gt.astype(\"float32\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    #  Precompute convolution kernel (generation matrix)\n",
    "    # ----------------------------------------------------------\n",
    "    def _get_convolution_ready_gt(self, len_obs):\n",
    "        \"\"\"Prepare generation-time convolution matrix for pytensor.scan.\"\"\"\n",
    "        gt = self._get_generation_time_interval()\n",
    "        conv_ready = np.zeros((len_obs - 1, len_obs), dtype=\"float32\")  # (t, lag) kernel\n",
    "\n",
    "        # fill kernel row by row: how past infections affect current time\n",
    "        for t in range(1, len_obs):\n",
    "            begin = np.maximum(0, t - len(gt) + 1)                     # start index\n",
    "            slice_update = gt[1 : t - begin + 1][::-1]                 # reverse order for convolution\n",
    "            conv_ready[t - 1, begin : begin + len(slice_update)] = slice_update\n",
    "\n",
    "        # wrap as shared tensor (constant node in computation graph)\n",
    "        return pytensor.shared(conv_ready)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    #  Model Construction\n",
    "    # ----------------------------------------------------------\n",
    "    def build(self):\n",
    "        \"\"\"Define full PyMC model.\"\"\"\n",
    "        p_delay = get_delay_distribution()                  # infection→confirmation delay\n",
    "        len_obs = len(self.observed)                        # number of observation days\n",
    "        conv_gt = self._get_convolution_ready_gt(len_obs)   # precomputed gen-time kernel\n",
    "        nonzero_days = self.observed.total.gt(0)            # mask for valid test counts\n",
    "\n",
    "        # model coordinate system for plotting & inference\n",
    "        coords = {\n",
    "            \"date\": self.observed.index.values,             # all observation dates\n",
    "            \"nonzero_date\": self.observed.index.values[nonzero_days],\n",
    "        }\n",
    "\n",
    "        # define probabilistic model\n",
    "        with pm.Model(coords=coords) as self.model:\n",
    "\n",
    "            # --- (1) Latent reproduction number Rₜ process ---\n",
    "            log_r_t = pm.GaussianRandomWalk(\"log_r_t\", sigma=0.035, dims=[\"date\"])  # random walk in log-space\n",
    "            r_t = pm.Deterministic(\"r_t\", pm.math.exp(log_r_t), dims=[\"date\"])      # Rₜ = exp(log_Rₜ)\n",
    "\n",
    "            # --- (2) Initial infection seed ---\n",
    "            seed = pm.Exponential(\"seed\", 1 / 0.02)          # small initial infection level\n",
    "            y0 = pt.zeros(len_obs, dtype=\"float32\")          # infection state array\n",
    "            y0 = pt.set_subtensor(y0[0], seed)               # set first day to seed value\n",
    "\n",
    "            # --- (3) Infection recurrence equation ---\n",
    "            def recurrence(t, gt_row, y, r_t):\n",
    "                # total new infections at day t = sum of past infections * Rₜ * generation weights\n",
    "                return pt.set_subtensor(y[t], pt.sum(r_t * y * gt_row))\n",
    "\n",
    "            # symbolic loop (scan) to simulate infections over time\n",
    "            outputs, _ = pytensor.scan(\n",
    "                fn=recurrence,                               # recurrence function\n",
    "                sequences=[pt.arange(1, len_obs), conv_gt],  # loop inputs\n",
    "                outputs_info=y0,                             # initial infection vector\n",
    "                non_sequences=r_t,                           # external variable\n",
    "                n_steps=len_obs - 1,                         # total time steps\n",
    "            )\n",
    "            infections = pm.Deterministic(\"infections\", outputs[-1], dims=[\"date\"])  # infection trajectory\n",
    "\n",
    "            # --- (4) Convolution: infections → observed positives ---\n",
    "            p_delay_shared = pytensor.shared(p_delay)         # delay distribution as tensor\n",
    "            convolved_full = conv1d(                         # apply convolution manually\n",
    "                infections.reshape((1, len_obs)).astype(\"float32\"),\n",
    "                p_delay_shared.reshape((1, len(p_delay))),\n",
    "                border_mode=\"full\",\n",
    "            )[0]\n",
    "            convolved = convolved_full[:len_obs]              # trim to observation window\n",
    "            test_adj_pos = pm.Deterministic(\"test_adjusted_positive\", convolved, dims=[\"date\"])\n",
    "\n",
    "            # --- (5) Exposure and expected positives ---\n",
    "            tests = pm.Data(\"tests\", self.observed.total.values.astype(\"float32\"), dims=[\"date\"])\n",
    "            exposure = pm.Deterministic(\n",
    "                \"exposure\",\n",
    "                pm.math.clip(tests, float(self.observed.total.max()) * 0.1, 1e9),  # avoid 0 exposure\n",
    "                dims=[\"date\"],\n",
    "            )\n",
    "            positive = pm.Deterministic(\"positive\", exposure * test_adj_pos, dims=[\"date\"])  # model output\n",
    "\n",
    "            # --- (6) Observed data ---\n",
    "            obs_pos = pm.Data(\"observed_positive\", self.observed.positive.values.astype(\"float32\"), dims=[\"date\"])\n",
    "            nonzero_obs_pos = pm.Data(\n",
    "                \"nonzero_observed_positive\",\n",
    "                self.observed.positive[nonzero_days.values].values.astype(\"float32\"),\n",
    "                dims=[\"nonzero_date\"],\n",
    "            )\n",
    "\n",
    "            # --- (7) Likelihood: observed positives follow NegBinomial ---\n",
    "            pm.NegativeBinomial(\n",
    "                \"nonzero_positive\",\n",
    "                mu=positive[nonzero_days.values],             # expected mean\n",
    "                alpha=pm.Gamma(\"alpha\", mu=6, sigma=1),       # dispersion prior\n",
    "                observed=nonzero_obs_pos,                     # actual observed data\n",
    "                dims=[\"nonzero_date\"],\n",
    "            )\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    #  Sampling (MCMC inference)\n",
    "    # ----------------------------------------------------------\n",
    "    def sample(\n",
    "        self,\n",
    "        cores=4,\n",
    "        chains=4,\n",
    "        tune=700,\n",
    "        draws=200,\n",
    "        target_accept=0.95,\n",
    "        init=\"jitter+adapt_diag\",\n",
    "    ):\n",
    "        \"\"\"Run NUTS MCMC to estimate posterior distributions.\"\"\"\n",
    "        # ensure model built before sampling\n",
    "        if self.model is None:\n",
    "            self.build()\n",
    "\n",
    "        with self.model:\n",
    "            # run sampler\n",
    "            self._trace = pm.sample(\n",
    "                draws=draws,           # number of posterior samples\n",
    "                tune=tune,             # number of warmup (adaptation) steps\n",
    "                chains=chains,         # independent MCMC chains\n",
    "                cores=cores,           # CPU cores to parallelize chains\n",
    "                target_accept=target_accept,  # acceptance rate for NUTS\n",
    "                init=init,             # initialization strategy\n",
    "            )\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e47305-7414-4c4c-a6e3-61b39ed6fa79",
   "metadata": {},
   "source": [
    "# Utils, plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89081d77-78cb-4b15-9753-a2c10a2e24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "#  Inference Summary Helper\n",
    "# ==============================================================\n",
    "\n",
    "def get_result(model):\n",
    "    \"\"\"Flatten and unpack posterior summary DataFrame for plotting.\"\"\"\n",
    "    result = summarize_inference_data(model.inference_data)\n",
    "    # unwrap nested structures into direct value arrays\n",
    "    for col in [\"mean\", \"median\", \"lower_80\", \"upper_80\",\n",
    "                \"infections\", \"test_adjusted_positive\"]:\n",
    "        result[col] = result[col].transform(lambda x: x.values)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#  Data Extraction\n",
    "# ==============================================================\n",
    "\n",
    "def get_data_by_region(df: pd.DataFrame, region: str, min_cases: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"Extract and trim data for a given region starting after threshold cases.\"\"\"\n",
    "    region_df = df[df[\"location\"] == region].copy()               # isolate region\n",
    "    first_valid = region_df[\"positive\"].ge(min_cases).idxmax()    # first day ≥ threshold\n",
    "    trimmed = region_df.loc[first_valid:]                         # keep later days only\n",
    "    return trimmed\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#  Visualization Functions\n",
    "# ==============================================================\n",
    "\n",
    "def plot_infections_and_tests(region, model, result):\n",
    "    \"\"\"Compare modeled infections and positive tests against reported data.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # model-based expectations\n",
    "    result.infections.plot(c=\"C2\", label=\"Expected primary infections\", ax=ax)\n",
    "    result.test_adjusted_positive.plot(c=\"C0\",\n",
    "                                       label=\"Expected positives (constant testing)\",\n",
    "                                       ax=ax)\n",
    "    result.test_adjusted_positive_raw.plot(c=\"C1\",\n",
    "                                           alpha=0.5,\n",
    "                                           style=\"--\",\n",
    "                                           label=\"Expected positives (raw)\",\n",
    "                                           ax=ax)\n",
    "\n",
    "    # observed data\n",
    "    model.observed.positive.plot(c=\"C7\", alpha=0.7, label=\"Reported positive tests\", ax=ax)\n",
    "\n",
    "    # formatting\n",
    "    fig.set_facecolor(\"w\")\n",
    "    ax.legend()\n",
    "    ax.set(title=f\"rt.live model inference for {region}\", ylabel=\"number of cases\")\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_effective_r_t(region, data_region, model, result):\n",
    "    \"\"\"Visualize effective reproduction number Rₜ with uncertainty bands.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.set(title=f\"Effective reproduction number for {region}\", ylabel=\"$R_e(t)$\")\n",
    "\n",
    "    # posterior samples for Rₜ\n",
    "    samples = model.trace[\"r_t\"].T\n",
    "    x = result.index\n",
    "\n",
    "    # color gradient by percentile level\n",
    "    percs = np.linspace(51, 99, 40)\n",
    "    colors = (percs - percs.min()) / (percs.max() - percs.min())\n",
    "    cmap = plt.get_cmap(\"Reds\")\n",
    "\n",
    "    # median line\n",
    "    result[\"median\"].plot(c=\"k\", ls=\"-\", ax=ax)\n",
    "\n",
    "    # credible intervals (shaded)\n",
    "    for i, p in enumerate(percs[::-1]):\n",
    "        upper = np.percentile(samples, p, axis=1)\n",
    "        lower = np.percentile(samples, 100 - p, axis=1)\n",
    "        ax.fill_between(x, upper, lower, color=cmap(colors[i]), alpha=0.8)\n",
    "\n",
    "    # threshold and observed comparison\n",
    "    ax.axhline(1.0, c=\"k\", lw=1, linestyle=\"--\")\n",
    "    ax.plot(data_region[\"reproduction_rate\"], label=\"Reported Rₜ\", c=\"C1\", alpha=0.6)\n",
    "    ax.legend()\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_posterior_predictive(region, data_region, model):\n",
    "    \"\"\"Plot posterior predictive realizations against observed case counts.\"\"\"\n",
    "    with model.model:\n",
    "        posterior_predictive = pm.sample_posterior_predictive(model.trace)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.plot(posterior_predictive[\"nonzero_positive\"].T, color=\"0.5\", alpha=0.05)  # simulated draws\n",
    "    ax.plot(data_region[\"positive\"].values, color=\"r\", label=\"Observed\")           # real data\n",
    "    ax.set(ylim=(0, 300_000))\n",
    "    ax.set_title(f\"Posterior nonzero positive cases for {region}\")\n",
    "    ax.legend()\n",
    "    sns.despine()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324c2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Russia ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndrew/miniconda3/envs/pymc5/lib/python3.11/site-packages/pymc/distributions/timeseries.py:291: UserWarning: Initial distribution not specified, defaulting to `Normal.dist(0, 100)`.You can specify an init_dist manually to suppress this warning.\n",
      "  warnings.warn(\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [log_r_t, seed, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/ndrew/miniconda3/envs/pymc5/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/ndrew/miniconda3/envs/pymc5/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndrew/miniconda3/envs/pymc5/lib/python3.11/site-packages/pytensor/scan/op.py:1576: RuntimeWarning: overflow encountered in cast\n",
      "  t_fn, n_steps = scan_perform_ext.perform(\n",
      "/home/ndrew/miniconda3/envs/pymc5/lib/python3.11/site-packages/pytensor/scan/op.py:1576: RuntimeWarning: overflow encountered in cast\n",
      "  t_fn, n_steps = scan_perform_ext.perform(\n",
      "/home/ndrew/miniconda3/envs/pymc5/lib/python3.11/site-packages/pytensor/scan/op.py:1576: RuntimeWarning: overflow encountered in cast\n",
      "  t_fn, n_steps = scan_perform_ext.perform(\n",
      "/home/ndrew/miniconda3/envs/pymc5/lib/python3.11/site-packages/pytensor/scan/op.py:1576: RuntimeWarning: overflow encountered in cast\n",
      "  t_fn, n_steps = scan_perform_ext.perform(\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "#  Imports and setup\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ensure base results directory exists\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# list of countries to process sequentially\n",
    "countries = [\"Russia\", \"Italy\", \"Germany\", \"France\"]\n",
    "\n",
    "# container to hold inference objects for later use\n",
    "results = {}\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#  Core fitting routine for one country\n",
    "# ==============================================================\n",
    "\n",
    "def fit_country(name, data):\n",
    "    \"\"\"Fit the GenerativeModel for one country and save outputs/plots.\"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    #  Data preparation\n",
    "    # ----------------------------\n",
    "    # extract country data and trim early zeros\n",
    "    region_data = get_data_by_region(data, name, min_cases=100)\n",
    "\n",
    "    # replace infinite / NaN values with zeros for numerical stability\n",
    "    region_data = region_data.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # cast key columns to float32 (required for PyTensor)\n",
    "    for col in [\"positive\", \"total\", \"reproduction_rate\"]:\n",
    "        if col in region_data.columns:\n",
    "            region_data[col] = region_data[col].astype(\"float32\")\n",
    "\n",
    "    # ----------------------------\n",
    "    #  Model build and sampling\n",
    "    # ----------------------------\n",
    "    gm = GenerativeModel(region=name, observed=region_data, buffer_days=10)\n",
    "    gm.build()  # define the model graph\n",
    "    gm.sample(  # run Bayesian inference (NUTS MCMC)\n",
    "        draws=1000,\n",
    "        tune=1000,\n",
    "        chains=4,\n",
    "        cores=8,\n",
    "        target_accept=0.95\n",
    "    )\n",
    "\n",
    "    # extract inference data and variable summaries\n",
    "    idata = gm.inference_data\n",
    "    summary = az.summary(idata, var_names=[\"r_t\", \"alpha\"]).round(3)\n",
    "\n",
    "    # create country-specific output directory\n",
    "    out_dir = os.path.join(\"results\", name.lower())\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # ==============================================================\n",
    "    #  Save Rₜ posterior summary\n",
    "    # ==============================================================\n",
    "    r_t = idata.posterior[\"r_t\"]                                 # posterior samples of Rₜ\n",
    "    r_t_mean = r_t.mean(dim=(\"chain\", \"draw\")).to_dataframe().reset_index()\n",
    "    r_t_hdi = az.hdi(r_t, hdi_prob=0.95).to_dataframe().reset_index()\n",
    "    r_t_df = pd.merge(r_t_mean, r_t_hdi, on=\"date\", how=\"left\")  # merge mean + intervals\n",
    "    r_t_df.rename(columns={\"r_t\": \"mean_r_t\",\n",
    "                           \"lower\": \"hdi_2.5\",\n",
    "                           \"upper\": \"hdi_97.5\"}, inplace=True)\n",
    "    r_t_df.to_csv(os.path.join(out_dir, f\"r_t_{name.lower()}.csv\"), index=False)\n",
    "\n",
    "    # ==============================================================\n",
    "    #  Save fitted new case trajectories\n",
    "    # ==============================================================\n",
    "    pos_post = idata.posterior[\"positive\"]                       # posterior predictions\n",
    "    pos_mean = pos_post.mean(dim=(\"chain\", \"draw\")).values[0]    # mean trajectory\n",
    "    pos_hdi = az.hdi(pos_post, hdi_prob=0.95).to_array().values  # 95% interval\n",
    "\n",
    "    df_fit = pd.DataFrame({\n",
    "        \"date\": region_data.index,\n",
    "        \"observed\": region_data[\"positive\"].values,\n",
    "        \"fitted_mean\": pos_mean,\n",
    "        \"hdi_2.5\": pos_hdi[0],\n",
    "        \"hdi_97.5\": pos_hdi[1]\n",
    "    })\n",
    "    df_fit.to_csv(os.path.join(out_dir, f\"fit_{name.lower()}.csv\"), index=False)\n",
    "\n",
    "    # ==============================================================\n",
    "    #  Diagnostic plots\n",
    "    # ==============================================================\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # --- (1) Effective Rₜ over time ---\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(r_t_df[\"date\"], r_t_df[\"mean_r_t\"], label=\"Mean Rₜ\")\n",
    "    plt.fill_between(r_t_df[\"date\"], r_t_df[\"hdi_2.5\"], r_t_df[\"hdi_97.5\"], alpha=0.2)\n",
    "    if \"reproduction_rate\" in region_data.columns:\n",
    "        plt.plot(region_data.index, region_data[\"reproduction_rate\"],\n",
    "                 \"--\", label=\"Reported Rₜ\")\n",
    "    plt.axhline(1, color=\"r\", linestyle=\":\")\n",
    "    plt.title(f\"{name} — Effective Rₜ\")\n",
    "    plt.legend()\n",
    "\n",
    "    # --- (2) Observed vs modeled new cases ---\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df_fit[\"date\"], df_fit[\"observed\"], label=\"Observed\", color=\"black\")\n",
    "    plt.plot(df_fit[\"date\"], df_fit[\"fitted_mean\"], label=\"Model mean\")\n",
    "    plt.fill_between(df_fit[\"date\"], df_fit[\"hdi_2.5\"], df_fit[\"hdi_97.5\"], alpha=0.2)\n",
    "    plt.title(f\"{name} — New Cases\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save combined plot\n",
    "    plt.savefig(os.path.join(out_dir, f\"summary_{name.lower()}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ==============================================================\n",
    "    #  Forecast evaluation (02–14 Dec 2020)\n",
    "    # ==============================================================\n",
    "    forecast_dates = pd.date_range(\"2020-12-02\", \"2020-12-14\")\n",
    "    df_forecast = df_fit[df_fit[\"date\"].isin(forecast_dates)].copy()\n",
    "\n",
    "    if not df_forecast.empty:\n",
    "        # compute error metrics\n",
    "        mae = mean_absolute_error(df_forecast[\"observed\"], df_forecast[\"fitted_mean\"])\n",
    "        rmse = mean_squared_error(df_forecast[\"observed\"],\n",
    "                                  df_forecast[\"fitted_mean\"],\n",
    "                                  squared=False)\n",
    "        mape = np.mean(np.abs((df_forecast[\"observed\"] - df_forecast[\"fitted_mean\"]) /\n",
    "                              np.clip(df_forecast[\"observed\"], 1, None))) * 100\n",
    "\n",
    "        # save metrics as small table\n",
    "        metrics = pd.DataFrame({\n",
    "            \"MAE\": [mae],\n",
    "            \"RMSE\": [rmse],\n",
    "            \"MAPE(%)\": [mape]\n",
    "        })\n",
    "        metrics.to_csv(os.path.join(out_dir,\n",
    "                                    f\"forecast_metrics_{name.lower()}.csv\"),\n",
    "                       index=False)\n",
    "        print(f\"{name}: MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.1f}%\")\n",
    "\n",
    "    # ==============================================================\n",
    "    #  Save inference artifacts\n",
    "    # ==============================================================\n",
    "    az.to_netcdf(idata, os.path.join(out_dir, f\"idata_{name.lower()}.nc\"))  # full posterior\n",
    "    summary.to_csv(os.path.join(out_dir, f\"summary_{name.lower()}.csv\"))    # textual summary\n",
    "    results[name] = {\"idata\": idata, \"summary\": summary}                    # store reference\n",
    "\n",
    "    print(f\"✓ {name} done — results saved to {out_dir}\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#  Run full pipeline for all countries\n",
    "# ==============================================================\n",
    "\n",
    "for c in countries:\n",
    "    print(f\"\\n=== {c} ===\")\n",
    "    fit_country(c, data)     # sequentially fit models\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#  Aggregate forecast metrics across all countries\n",
    "# ==============================================================\n",
    "\n",
    "all_metrics = []\n",
    "for c in countries:\n",
    "    metrics_path = f\"results/{c.lower()}/forecast_metrics_{c.lower()}.csv\"\n",
    "    if os.path.exists(metrics_path):\n",
    "        m = pd.read_csv(metrics_path)\n",
    "        m.insert(0, \"Country\", c)          # add country column\n",
    "        all_metrics.append(m)\n",
    "\n",
    "# combine and export single summary CSV if data available\n",
    "if all_metrics:\n",
    "    combined = pd.concat(all_metrics)\n",
    "    combined.to_csv(\"results/forecast_summary.csv\", index=False)\n",
    "    print(\"Combined forecast metrics saved to results/forecast_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Долго считалось, переписал conv1d вручную. Расчет очень долгий, не досчитался"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
